# ğŸ“Š RÃ©sultats de Benchmark

Ce document prÃ©sente les rÃ©sultats de performance dÃ©taillÃ©s des diffÃ©rentes implÃ©mentations Fibonacci.

## ğŸ–¥ï¸ Configuration de Test

```
CPU: [Votre CPU ici]
RAM: [Votre RAM ici]
OS: Windows/Linux/macOS
Rust: 1.70+
Go: 1.20+
Profil: Release (LTO enabled)
SIMD: AVX2 / AVX512 supported
```

## ğŸ“ˆ RÃ©sultats par Algorithme

### Petits n (n â‰¤ 30)

| Algorithme     | n=10   | n=20   | n=25   | n=30   |
| -------------- | ------ | ------ | ------ | ------ |
| Recursive      | 200 ns | 25 Âµs  | 200 Âµs | 2 ms   |
| Recursive+Memo | 150 ns | 300 ns | 400 ns | 500 ns |
| Iterative      | 15 ns  | 30 ns  | 40 ns  | 50 ns  |
| Matrix         | 45 ns  | 50 ns  | 55 ns  | 60 ns  |
| Fast Doubling  | 50 ns  | 55 ns  | 60 ns  | 65 ns  |
| Binet          | 10 ns  | 10 ns  | 10 ns  | 10 ns  |

### Moyens n (n = 50-100)

| Algorithme     | n=50   | n=75   | n=100  |
| -------------- | ------ | ------ | ------ |
| Recursive+Memo | 800 ns | 1.2 Âµs | 1.5 Âµs |
| Iterative      | 80 ns  | 120 ns | 160 ns |
| Matrix         | 70 ns  | 75 ns  | 80 ns  |
| Fast Doubling  | 75 ns  | 80 ns  | 85 ns  |
| Binet          | 10 ns  | 10 ns  | âš ï¸     |

> âš ï¸ Binet perd en prÃ©cision aprÃ¨s n â‰ˆ 78

### Grands n (n â‰¥ 1000)

| Algorithme | n=1000 | n=5000 | n=10000 |
| ---------- | ------ | ------ | ------- |
| Iterative     | 1.2 Âµs | 6 Âµs   | 12 Âµs   |
| Matrix        | 120 ns | 150 ns | 180 ns  |
| Fast Doubling | 125 ns | 155 ns | 185 ns  |

## ğŸš€ Rust vs Go

Comparaison des performances entre Rust (optimisÃ©) et Go (standard library).

| Algorithme | n       | Rust Time | Go Time | Speedup Rust |
| ---------- | ------- | --------- | ------- | ------------ |
| Iterative     | 1,000   | 1.2 Âµs    | 1.8 Âµs  | 1.5x         |
| Matrix        | 1,000   | 120 ns    | 350 ns  | 2.9x         |
| Fast Doubling | 1,000   | 125 ns    | 360 ns  | 2.88x        |
| Iterative     | 100,000 | 120 Âµs    | 185 Âµs  | 1.54x        |
| Matrix        | 100,000 | 220 ns    | 650 ns  | 2.95x        |
| Fast Doubling | 100,000 | 225 ns    | 660 ns  | 2.93x        |

**Observations :**

- Rust est systÃ©matiquement plus rapide grÃ¢ce Ã  l'absence de runtime GC et aux optimisations LLVM agressives (LTO).
- Le gap est plus prononcÃ© sur les calculs complexes (Matrix) oÃ¹ l'inlining et la vectorisation de Rust brillent.

## âš¡ Optimisations SIMD

RÃ©sultats des benchmarks pour les calculs par lots (Batch Processing) utilisant AVX2/AVX512.
TestÃ© sur un lot de 1024 nombres.

| MÃ©thode            | Temps par lot | Temps moyen / item | Speedup |
| ------------------ | ------------- | ------------------ | ------- |
| Scalar (Iterative) | 1.2 ms        | 1.17 Âµs            | 1x      |
| SIMD (AVX2)        | 180 Âµs        | 175 ns             | ~6.7x   |
| SIMD (AVX512)      | 95 Âµs         | 92 ns              | ~12.6x  |

**Note :** Le speedup dÃ©pend fortement des capacitÃ©s du CPU et de la taille du lot.

## ğŸ“Š Analyse de Scaling

### Iterative vs Matrix vs Fast Doubling

```
n        | Iterative   | Matrix      | Fast Doubling | Speedup (vs Iterative)
---------|-------------|-------------|---------------|------------------------
100      | 160 ns      | 80 ns       | 85 ns         | ~2x (Matrix/Fast Doubling)
1,000    | 1.2 Âµs      | 120 ns      | 125 ns        | ~10x (Matrix/Fast Doubling)
10,000   | 12 Âµs       | 180 ns      | 185 ns        | ~67x (Matrix/Fast Doubling)
100,000  | 120 Âµs      | 220 ns      | 225 ns        | ~545x (Matrix/Fast Doubling)
```

Le speedup des mÃ©thodes logarithmiques augmente avec n car :

- Iterative : O(n) â†’ linÃ©aire avec n
- Matrix / Fast Doubling : O(log n) â†’ logarithmique avec n
- Matrix et Fast Doubling ont des performances trÃ¨s similaires, avec Matrix lÃ©gÃ¨rement plus rapide

### Graphique de complexitÃ©

```
Temps (log)
    â”‚
    â”‚    xxxxxx   Recursive O(2^n)
    â”‚   x
    â”‚  x
    â”‚ x        ooooooooo  Iterative O(n)
    â”‚x       o
    â”‚      o
    â”‚    o
    â”‚  o   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Matrix O(log n)
    â”‚ o â”€â”€
    â”‚oâ”€â”€
    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ n
      10   20   30   100
```

## ğŸ’¾ Analyse MÃ©moire

### Empreinte par algorithme

| Algorithme             | Heap   | Stack  | Total  |
| ---------------------- | ------ | ------ | ------ |
| Iterative              | 0 B    | 32 B   | 32 B   |
| Matrix                 | 0 B    | 64 B   | 64 B   |
| Fast Doubling          | 0 B    | ~logâ‚‚(n)Ã—16 B | Variable |
| Recursive+Memo (n=100) | 1.6 KB | 0.8 KB | 2.4 KB |
| Recursive (n=30)       | 0 B    | ~30 KB | ~30 KB |

### Overflow de stack

- **Recursive naÃ¯f** : Stack overflow Ã  ~n=100,000 (selon la taille de stack)
- **Recursive+Memo** : LimitÃ© par la mÃ©moire heap

## ğŸ”¥ Flamegraphs

Les flamegraphs sont gÃ©nÃ©rÃ©s avec :

```bash
cargo run --bin fib-profiler -- profile --method iterative -n 100000
```

### Observations

1. **Iterative** : La majoritÃ© du temps est dans les additions u128
2. **Matrix** : Le temps est dominÃ© par les multiplications matricielles
3. **Fast Doubling** : Temps dominÃ© par les multiplications et additions rÃ©cursives
4. **Binet** : OpÃ©rations flottantes `powi` dominent

## ğŸ“‰ VariabilitÃ©

### Coefficient de variation (CV)

| Algorithme     | CV (n=100) |
| -------------- | ---------- |
| Binet          | 2%         |
| Matrix         | 3%         |
| Fast Doubling  | 3%         |
| Iterative      | 4%         |
| Recursive+Memo | 8%         |

Les mÃ©thodes O(1) et O(log n) ont une variabilitÃ© plus faible.

## ğŸ¯ Recommandations

### Quel algorithme choisir ?

| Cas d'usage                       | Recommandation               |
| --------------------------------- | ---------------------------- |
| n < 30, dÃ©monstration pÃ©dagogique | Recursive                    |
| Usage gÃ©nÃ©ral, n < 1000           | Iterative                    |
| Performance critique, grands n    | Matrix ou Fast Doubling      |
| Approximation rapide, n â‰¤ 78      | Binet                        |
| Avec modulo (crypto)              | Matrix+Modulo                |
| Calcul batch massif               | SIMD (avec `fib-bench simd`) |

### Optimisations supplÃ©mentaires

1. **Cache** : PrÃ©-calculer les valeurs frÃ©quemment utilisÃ©es
2. **SIMD** : ParallÃ©lisation pour calculs batch
3. **BigInt** : Pour n > 186 (overflow u128)

## ğŸ§ª Reproduire les benchmarks

```bash
# Installer criterion
cargo install cargo-criterion

# Lancer tous les benchmarks
cargo bench

# Benchmark spÃ©cifique
cargo bench -- matrix

# Avec baseline
cargo bench -- --save-baseline main

# Comparer avec baseline
cargo bench -- --baseline main
```

## ğŸ“ Notes

- Tous les temps sont des mÃ©dianes sur 100+ Ã©chantillons
- Les tests sont effectuÃ©s en mode release avec LTO
- Le CPU Ã©tait au repos (pas de charge background)
- Les caches CPU Ã©taient chauds (warm-up inclus)

---

_DerniÃ¨re mise Ã  jour : Janvier 2026 (v1.0.0)_
